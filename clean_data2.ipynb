{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sjoert.stellar\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from cleaning_functions import q_cuts,field_check,filter_split,flux_unc_val\n",
    "from astropy import coordinates as coord\n",
    "import json\n",
    "from numpyencoder import NumpyEncoder\n",
    "\n",
    "sjoertpath = r'C:\\Users\\timvd\\Documents\\Uni 2023-2024\\First Research Project\\Data\\Sjoert_Flares'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code to remove all clean files and clean logs from the sjoert_flares directory.\n",
    "def remove_clean():\n",
    "    for folder in os.listdir(sjoertpath)[::-1]:\n",
    "        if 'ZTF' in folder:\n",
    "            folderpath = os.path.join(sjoertpath,folder)\n",
    "            for file in os.listdir(folderpath):\n",
    "                if 'clean' in file:\n",
    "                    os.remove(os.path.join(folderpath,file))\n",
    "# remove_clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(datapath,ZTF_ID,savepath=None,verbose=False):\n",
    "    \"\"\"Cleans ZTF batch request data using the qcuts function. The removed data is neatly logged on a per filter - per field basis. The cleaning\n",
    "    now works in such a way that only the data from the primary field (defined as the field in which most measurements were made) is used.\n",
    "    The uncertainty on the flux measurements is validated and subsequently updated following the method of the ZFPS user guide: \n",
    "    https://web.ipac.caltech.edu/staff/fmasci/ztf/zfps_userguide.pdf. The cleaned data contains: time in jd, forced difference image PSF-fit flux [DN],\n",
    "      the 1-sigma uncertainty in the forced difference image PSF-fit flux [DN], the photometric zeropoint for difference image [mag] and the filter \n",
    "      (one of ZTF_g, ZTF_r and ZTF_i). The cleaning log contains, for every field in every filter, whether there are even viable measurements and if\n",
    "      there are if the field in question is the primary field, what the median zeropoint is, what the standard deviation of the zeropoints is, how\n",
    "      many of the data points were removed in cleaning and the median chi-square of the datapoints before cleaning. For every filter the median \n",
    "      chi-square after cleaning is saved only for the primary field - this will differ only slightly from the median chi-square before cleaning. \n",
    "      Both cleaned data and cleaning log are saved as json files in the form \"(ZTF_ID)_clean_data.json\" and \"(ZTF_ID)_clean_log.json\".\n",
    "      \n",
    "      IMPORTANT: dependencies are the numpy, pandas, json and os packages as well as a special json NumpyEncoder by Hunter M. Allen (https://pypi.org/project/numpyencoder/).\n",
    "\n",
    "    Args:\n",
    "        datapath (str): Path to the raw data in the form path\\to\\data\\batchf_reqxxxxxxxxxxxxxxxxx_lc.txt.\n",
    "        ZTF_ID (str): ZTF identifier of the transient.\n",
    "        savepath (str, optional): Path to folder in which clean data and cleaning log will be saved. Defaults to None, in which case data is printed if verbose is True, otherwise it is lost.\n",
    "        verbose (bool, optional): Controls the (amount of) print statements in the function. Defaults to False.\n",
    "    \"\"\"\n",
    "    #Read in the raw data from the data path as a Pandas DataFrame. \n",
    "    columns = ['sindex', 'field', 'ccdid', 'qid', 'filter', 'pid', 'infobitssci', 'sciinpseeing', 'scibckgnd', 'scisigpix', 'zpmaginpsci', 'zpmaginpsciunc', 'zpmaginpscirms', 'clrcoeff', 'clrcoeffunc', 'ncalmatches', 'exptime', 'adpctdif1', 'adpctdif2', 'diffmaglim', 'zpdiff', 'programid', 'jd', 'rfid', 'forcediffimflux', 'forcediffimfluxunc', 'forcediffimsnr', 'forcediffimchisq', 'forcediffimfluxap', 'forcediffimfluxuncap', 'forcediffimsnrap', 'aperturecorr', 'dnearestrefsrc', 'nearestrefmag', 'nearestrefmagunc', 'nearestrefchi', 'nearestrefsharp', 'refjdstart', 'refjdend', 'procstatus']\n",
    "    dtypes = [(columns[x],float) for x in range(len(columns))]\n",
    "    dtypes[4] = ('filter',r'U8')\n",
    "    data = pd.DataFrame(np.genfromtxt(datapath,skip_header=53,dtype=dtypes))\n",
    "\n",
    "    clean_data_full = pd.DataFrame() #an empty frame on which the data from every filter will be vertically stacked.\n",
    "    iok = q_cuts(data) #very first quality check, mask array of good data points.\n",
    "    data_ok = data[iok]\n",
    "    logdict = {} #dictionary that will form the log.json file\n",
    "\n",
    "    filters = np.unique(data['filter'])\n",
    "    filtermasks = [data['filter'] == f for f in filters]\n",
    "    # fields,field_counts = np.unique(data['field'],return_counts=True) #return_counts for picking the primary field\n",
    "    fields,_ = np.unique(data_ok['field'],return_counts=True) #Do we want the primary field on data or on data_ok?\n",
    "    fieldmasks = [data['field'] == fid for fid in fields]\n",
    "\n",
    "    if iok.sum() == 0: #this might occur, this prevents an error\n",
    "        print(f\"{ZTF_ID}: no viable data found in the batch request. Proceeding to next file.\")\n",
    "        return \n",
    "    \n",
    "    for i,filter in enumerate(filters):\n",
    "            logdict[filter] = {}\n",
    "            logdict[filter][\"no_viable_data\"] = 0 #can be used for a check when loading in the data; if this is True then the data is useless in this particular filter \n",
    "            filtermask = filtermasks[i]\n",
    "            iok_filter = (iok * filtermask) #this checks if something is ok according to qcuts and is in a certain filter. Has the same len as data.\n",
    "            \n",
    "            if iok_filter.sum() == 0: #this might occur, this prevents an error\n",
    "                print(f\"{ZTF_ID}: no viable data found in {filter}. Proceeding to next filter.\")\n",
    "                logdict[filter][\"no_viable_data\"] = 1\n",
    "                continue\n",
    "\n",
    "            #If we take the primary field on a per filter basis use three lines below.\n",
    "            data_ok_filter = data[iok_filter]\n",
    "            filter_field_counts = [np.sum(data_ok_filter['field'] == fid) for fid in fields] #count for each field we know to have in the uncleaned data how often it appears in this filter. Might yield 0's! \n",
    "            primary_field = [c == np.max(filter_field_counts) for c in filter_field_counts] #should be this one if we want to pick the primary on a per filter basis\n",
    "\n",
    "            for j,fid in enumerate(fields):\n",
    "                field_mask = fieldmasks[j]\n",
    "                iok_filter_field = iok_filter * field_mask #this checks if something is ok according to qcuts, is in a certain filter and is in a certain field. Has the same len as data.\n",
    "\n",
    "                logdict[filter][fid] = {}\n",
    "                if iok_filter_field.sum() == 0: #this might occur, this prevents an error\n",
    "                    print(f\"{ZTF_ID}: no viable data found in field {fid} of filter {filter}. Proceeding to next field for this filter.\")\n",
    "                    logdict[filter][fid][\"no_viable_data\"] = 1 #can be used for a check when loading in the data; if this is True then the data is useless in this particular field / filter combo\n",
    "                    continue\n",
    "\n",
    "                data_ok_filter_field = data[iok_filter_field]\n",
    "                data_filter_field = data[filtermask*field_mask] #this is the uncleaned data of this field in this filter\n",
    "                zeropoint = data_ok_filter_field['zpdiff'].values\n",
    "\n",
    "                logdict[filter][fid] = {\"primary_field\":int(primary_field[j]),\n",
    "                                        \"median_zeropoint\":np.median(zeropoint),'std_zeropoint':np.std(zeropoint),\n",
    "                                        \"removed_in_cleaning\":np.sum(np.invert(iok_filter_field)),\n",
    "                                        \"amount_before_cleaning\": len(iok_filter_field),\n",
    "                                        \"median_chi2\":np.median(data_filter_field['forcediffimchisq']),\n",
    "                                            \"no_viable_data\":0}\n",
    "\n",
    "                if primary_field[j]:\n",
    "                    #correct the errors of the clean data in this filter (only on the primary field)\n",
    "                    new_unc = np.array(flux_unc_val(data_ok_filter_field))\n",
    "                    #the median chi squared after is that of the good data in the primary field of the respective filter\n",
    "                    logdict[filter][\"median_chi2_after\"] = np.median(data_ok_filter_field['forcediffimchisq']) \n",
    "                    clean_data_filt = pd.DataFrame({'time':data_ok_filter_field['jd'],'flux':data_ok_filter_field['forcediffimflux'],\n",
    "                                                   'flux_unc':new_unc,'zeropoint':data_ok_filter_field['zpdiff'],\n",
    "                                                   'filter':data_ok_filter_field['filter']})\n",
    "                    clean_data_full = pd.concat([clean_data_full,clean_data_filt],ignore_index=True)\n",
    "        \n",
    "    if savepath != None:\n",
    "        # clean_data_full.to_json(os.path.join(savepath,str(ZTF_ID)+'_clean_data.json'))\n",
    "        clean_data_full.to_csv(os.path.join(savepath,str(ZTF_ID)+'_clean_data.txt'),sep='\\t',index=None,header=None,mode='a')\n",
    "        with open(os.path.join(savepath,str(ZTF_ID)+'_clean_log.json'),'w') as outfile:\n",
    "            json.dump(logdict,outfile,indent=4,ensure_ascii=False,separators=(',',':'),cls=NumpyEncoder)\n",
    "    else:\n",
    "        print('No savepath provided. Dumping results, shown if verbose set to True.')\n",
    "        if verbose:\n",
    "            print(clean_data_full.to_markdown())\n",
    "            print()\n",
    "            print(logdict)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZTF20aagkqky: no viable data found in field 1869.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF20aabhraq: no viable data found in field 1510.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF20aabhraq: no viable data found in field 1511.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF20aabhraq: no viable data found in field 1510.0 of filter ZTF_r. Proceeding to next field for this filter.\n",
      "ZTF19adcddzk: no viable data found in field 1749.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19adawqog: no viable data found in field 1711.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19accdntg: no viable data found in field 1593.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19acaakoh: no viable data found in field 1831.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19abzrhgq: no viable data found in field 1347.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19abxwbjp: no viable data found in field 1612.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19abisdrk: no viable data found in ZTF_i. Proceeding to next filter.\n",
      "ZTF19abiptrq: no viable data found in field 599.0 of filter ZTF_g. Proceeding to next field for this filter.\n",
      "ZTF19abiptrq: no viable data found in field 1644.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19abclykm: no viable data found in field 1860.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19aazdsch: no viable data found in field 1492.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19aavihif: no viable data found in field 1725.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19aaujlpo: no viable data found in field 1624.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19aatubsj: no viable data found in field 1678.0 of filter ZTF_g. Proceeding to next field for this filter.\n",
      "ZTF19aatubsj: no viable data found in field 1678.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19aasejul: no viable data found in field 1624.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19aariszh: no viable data found in field 1621.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19aaqesdr: no viable data found in field 1720.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19aapreis: no viable data found in field 1589.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19aaohxwd: no viable data found in ZTF_g. Proceeding to next filter.\n",
      "ZTF19aanglav: no viable data found in field 1789.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19aanglav: no viable data found in field 1790.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19aamsgro: no viable data found in field 1616.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19aalfali: no viable data found in field 1831.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19aakjfcm: no viable data found in field 1800.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF19aaiqmgl: no viable data found in field 1458.0 of filter ZTF_g. Proceeding to next field for this filter.\n",
      "ZTF19aaiqmgl: no viable data found in field 1458.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18adbifqw: no viable data found in field 1623.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18acvvudh: no viable data found in field 1457.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18acvhhgk: no viable data found in field 1708.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18acsvwfr: no viable data found in field 1641.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18acryhcb: no viable data found in field 1574.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18acqywlx: no viable data found in field 1708.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18acmxowe: no viable data found in field 1394.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18acgqweq: no viable data found in field 1399.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18acgqweq: no viable data found in field 1400.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18acefilj: no viable data found in field 1615.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18acbztng: no viable data found in field 1510.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18abvmqur: no viable data found in field 662.0 of filter ZTF_g. Proceeding to next field for this filter.\n",
      "ZTF18abvmqur: no viable data found in field 661.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18abvmqur: no viable data found in field 662.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18abtizze: no viable data found in field 1488.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18abtizze: no viable data found in field 1488.0 of filter ZTF_r. Proceeding to next field for this filter.\n",
      "ZTF18abshxig: no viable data found in field 1673.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18abjjkeo: no viable data found in field 1871.0 of filter ZTF_g. Proceeding to next field for this filter.\n",
      "ZTF18abjjkeo: no viable data found in field 1871.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18aauosxv: no viable data found in field 1721.0 of filter ZTF_g. Proceeding to next field for this filter.\n",
      "ZTF18aauosxv: no viable data found in field 1721.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18aanlzzf: no viable data found in field 1760.0 of filter ZTF_g. Proceeding to next field for this filter.\n",
      "ZTF18aanlzzf: no viable data found in field 1761.0 of filter ZTF_g. Proceeding to next field for this filter.\n",
      "ZTF18aanlzzf: no viable data found in field 1760.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18aanlzzf: no viable data found in field 1761.0 of filter ZTF_i. Proceeding to next field for this filter.\n",
      "ZTF18aajupnt: no viable data found in field 1759.0 of filter ZTF_i. Proceeding to next field for this filter.\n"
     ]
    }
   ],
   "source": [
    "def clean_iter():\n",
    "    for folder in os.listdir(sjoertpath)[::-1]:\n",
    "        if \"ZTF\" in folder:\n",
    "            folderpath = os.path.join(sjoertpath,folder)\n",
    "            ztf_id = os.path.split(folderpath)[-1]\n",
    "            for file in os.listdir(folderpath):\n",
    "                if 'clean' not in file and 'parameters' not in file:\n",
    "                    filepath = os.path.join(folderpath,file)\n",
    "                    try:\n",
    "                        clean_data(filepath,ztf_id,savepath=folderpath)\n",
    "                    except ValueError as err:\n",
    "                        print(err)\n",
    "                        print(folderpath,ztf_id)\n",
    "                        return\n",
    "                    \n",
    "# clean_iter()     \n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing adding a header after the fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just a random file\n",
    "testpath = r'C:\\Users\\timvd\\Documents\\Uni 2023-2024\\First Research Project\\Data\\Sjoert_Flares\\ZTF18abvmqur\\ZTF18abvmqur_clean_data.txt'\n",
    "\n",
    "def make_header(logfilepath):\n",
    "    logfilename = os.path.split(logfilepath)[-1]\n",
    "    logstr = f\"#See {logfilename} for thorough overview of cleaning process.\\n#Headers: time [jd], flux [ujy], flux uncertainty [ujy], zeropoint [mag], filter\"\n",
    "    with open(logfilepath,'r') as logfile:\n",
    "        logdata = json.load(logfile)\n",
    "    filters = [\"ZTF_g\",\"ZTF_r\",\"ZTF_i\"]\n",
    "    for filt in filters:\n",
    "        try:\n",
    "            filter_data = logdata[filt]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        if filter_data['no_viable_data']:\n",
    "            if filt =='ZTF_g' or filt == \"ZTF_r\":\n",
    "                logstr += f'No viable data in {filt}. This data will thus not be fitted.\\n#'\n",
    "            else:\n",
    "                logstr += f'No viable data in {filt}.\\n#'\n",
    "    logstr += '\\n'\n",
    "    return logstr\n",
    "\n",
    "def line_prepender(filename):\n",
    "    filedir,ztf_clean_data = os.path.split(filename)\n",
    "    logdir = os.path.join(filedir,ztf_clean_data.split(\"_\")[0]+\"_clean_log.json\")\n",
    "    headerstring = make_header(logdir)\n",
    "    with open(filename, 'r+') as f:\n",
    "        content = f.read()\n",
    "        if '#See' in content:\n",
    "            return\n",
    "        f.seek(0, 0)\n",
    "        f.write(headerstring.rstrip('\\r\\n') + '\\n' + content)\n",
    "\n",
    "\n",
    "# make_header(r'C:\\Users\\timvd\\Documents\\Uni 2023-2024\\First Research Project\\Data\\Sjoert_Flares\\ZTF18abvmqur\\ZTF18abvmqur_clean_log.json')\n",
    "def prepend_sjoert_files():\n",
    "    for folder in os.listdir(sjoertpath)[::-1]:\n",
    "            if \"ZTF\" in folder:\n",
    "                print(folder)\n",
    "                folderpath = os.path.join(sjoertpath,folder)\n",
    "                ztf_id = os.path.split(folderpath)[-1]\n",
    "                for file in os.listdir(folderpath):\n",
    "                    if \"clean_data.txt\" in file:        \n",
    "                        filepath = os.path.join(folderpath,file)\n",
    "                        line_prepender(filepath)\n",
    "                        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
