{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sjoert.stellar\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from cleaning_functions import q_cuts,field_check,filter_split,flux_unc_val,clean_data\n",
    "from astropy import coordinates as coord\n",
    "\n",
    "sjoertpath = r'C:\\Users\\timvd\\Documents\\Uni 2023-2024\\First Research Project\\Data\\Sjoert_Flares'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timvd\\Documents\\Uni 2023-2024\\First Research Project\\Data\\Sjoert_Flares\\ZTF19abiptrq\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sindex</th>\n",
       "      <th>field</th>\n",
       "      <th>ccdid</th>\n",
       "      <th>qid</th>\n",
       "      <th>filter</th>\n",
       "      <th>pid</th>\n",
       "      <th>infobitssci</th>\n",
       "      <th>sciinpseeing</th>\n",
       "      <th>scibckgnd</th>\n",
       "      <th>scisigpix</th>\n",
       "      <th>...</th>\n",
       "      <th>forcediffimsnrap</th>\n",
       "      <th>aperturecorr</th>\n",
       "      <th>dnearestrefsrc</th>\n",
       "      <th>nearestrefmag</th>\n",
       "      <th>nearestrefmagunc</th>\n",
       "      <th>nearestrefchi</th>\n",
       "      <th>nearestrefsharp</th>\n",
       "      <th>refjdstart</th>\n",
       "      <th>refjdend</th>\n",
       "      <th>procstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ZTF_g</td>\n",
       "      <td>5.484412e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1651</td>\n",
       "      <td>83.2122</td>\n",
       "      <td>9.80441</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.156464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.458276e+06</td>\n",
       "      <td>2.458348e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ZTF_r</td>\n",
       "      <td>5.514343e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8785</td>\n",
       "      <td>154.5100</td>\n",
       "      <td>8.24687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042127</td>\n",
       "      <td>1.072413</td>\n",
       "      <td>0.298118</td>\n",
       "      <td>19.066</td>\n",
       "      <td>0.098</td>\n",
       "      <td>5.831</td>\n",
       "      <td>0.534</td>\n",
       "      <td>2.458285e+06</td>\n",
       "      <td>2.458367e+06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ZTF_r</td>\n",
       "      <td>5.564411e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4364</td>\n",
       "      <td>142.3760</td>\n",
       "      <td>5.10206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109556</td>\n",
       "      <td>1.225016</td>\n",
       "      <td>0.298118</td>\n",
       "      <td>19.066</td>\n",
       "      <td>0.098</td>\n",
       "      <td>5.831</td>\n",
       "      <td>0.534</td>\n",
       "      <td>2.458285e+06</td>\n",
       "      <td>2.458367e+06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ZTF_r</td>\n",
       "      <td>5.594201e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6128</td>\n",
       "      <td>143.0450</td>\n",
       "      <td>5.28476</td>\n",
       "      <td>...</td>\n",
       "      <td>2.152287</td>\n",
       "      <td>1.070403</td>\n",
       "      <td>0.298118</td>\n",
       "      <td>19.066</td>\n",
       "      <td>0.098</td>\n",
       "      <td>5.831</td>\n",
       "      <td>0.534</td>\n",
       "      <td>2.458285e+06</td>\n",
       "      <td>2.458367e+06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ZTF_g</td>\n",
       "      <td>5.594857e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7016</td>\n",
       "      <td>77.8977</td>\n",
       "      <td>7.32948</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.162553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.458276e+06</td>\n",
       "      <td>2.458348e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>1868.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ZTF_r</td>\n",
       "      <td>2.467227e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7547</td>\n",
       "      <td>174.9880</td>\n",
       "      <td>8.67583</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.494993</td>\n",
       "      <td>1.044787</td>\n",
       "      <td>0.298118</td>\n",
       "      <td>19.066</td>\n",
       "      <td>0.098</td>\n",
       "      <td>5.831</td>\n",
       "      <td>0.534</td>\n",
       "      <td>2.458285e+06</td>\n",
       "      <td>2.458367e+06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>1869.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ZTF_r</td>\n",
       "      <td>2.469226e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2862</td>\n",
       "      <td>176.2400</td>\n",
       "      <td>7.12707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.748987</td>\n",
       "      <td>1.067333</td>\n",
       "      <td>0.298118</td>\n",
       "      <td>19.066</td>\n",
       "      <td>0.098</td>\n",
       "      <td>5.831</td>\n",
       "      <td>0.534</td>\n",
       "      <td>2.458285e+06</td>\n",
       "      <td>2.458367e+06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>1870.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ZTF_g</td>\n",
       "      <td>2.469279e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5212</td>\n",
       "      <td>94.9387</td>\n",
       "      <td>6.81256</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.120983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.458276e+06</td>\n",
       "      <td>2.458348e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>1871.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ZTF_g</td>\n",
       "      <td>2.474249e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9565</td>\n",
       "      <td>95.6172</td>\n",
       "      <td>4.82302</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.132190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.458276e+06</td>\n",
       "      <td>2.458348e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>1872.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ZTF_r</td>\n",
       "      <td>2.474277e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0390</td>\n",
       "      <td>179.8710</td>\n",
       "      <td>6.40694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496702</td>\n",
       "      <td>1.067113</td>\n",
       "      <td>0.298118</td>\n",
       "      <td>19.066</td>\n",
       "      <td>0.098</td>\n",
       "      <td>5.831</td>\n",
       "      <td>0.534</td>\n",
       "      <td>2.458285e+06</td>\n",
       "      <td>2.458367e+06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1873 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sindex  field  ccdid  qid filter           pid  infobitssci  \\\n",
       "0        0.0  599.0    9.0  4.0  ZTF_g  5.484412e+11          0.0   \n",
       "1        1.0  599.0    9.0  4.0  ZTF_r  5.514343e+11          0.0   \n",
       "2        2.0  599.0    9.0  4.0  ZTF_r  5.564411e+11          0.0   \n",
       "3        3.0  599.0    9.0  4.0  ZTF_r  5.594201e+11          0.0   \n",
       "4        4.0  599.0    9.0  4.0  ZTF_g  5.594857e+11          0.0   \n",
       "...      ...    ...    ...  ...    ...           ...          ...   \n",
       "1868  1868.0  599.0    9.0  4.0  ZTF_r  2.467227e+12          0.0   \n",
       "1869  1869.0  599.0    9.0  4.0  ZTF_r  2.469226e+12          0.0   \n",
       "1870  1870.0  599.0    9.0  4.0  ZTF_g  2.469279e+12          0.0   \n",
       "1871  1871.0  599.0    9.0  4.0  ZTF_g  2.474249e+12          0.0   \n",
       "1872  1872.0  599.0    9.0  4.0  ZTF_r  2.474277e+12          0.0   \n",
       "\n",
       "      sciinpseeing  scibckgnd  scisigpix  ...  forcediffimsnrap  aperturecorr  \\\n",
       "0           2.1651    83.2122    9.80441  ...               NaN      1.156464   \n",
       "1           1.8785   154.5100    8.24687  ...          0.042127      1.072413   \n",
       "2           3.4364   142.3760    5.10206  ...         -0.109556      1.225016   \n",
       "3           1.6128   143.0450    5.28476  ...          2.152287      1.070403   \n",
       "4           2.7016    77.8977    7.32948  ...               NaN      1.162553   \n",
       "...            ...        ...        ...  ...               ...           ...   \n",
       "1868        1.7547   174.9880    8.67583  ...         -2.494993      1.044787   \n",
       "1869        2.2862   176.2400    7.12707  ...         -0.748987      1.067333   \n",
       "1870        2.5212    94.9387    6.81256  ...               NaN      1.120983   \n",
       "1871        2.9565    95.6172    4.82302  ...               NaN      1.132190   \n",
       "1872        2.0390   179.8710    6.40694  ...          0.496702      1.067113   \n",
       "\n",
       "      dnearestrefsrc  nearestrefmag  nearestrefmagunc  nearestrefchi  \\\n",
       "0                NaN            NaN               NaN            NaN   \n",
       "1           0.298118         19.066             0.098          5.831   \n",
       "2           0.298118         19.066             0.098          5.831   \n",
       "3           0.298118         19.066             0.098          5.831   \n",
       "4                NaN            NaN               NaN            NaN   \n",
       "...              ...            ...               ...            ...   \n",
       "1868        0.298118         19.066             0.098          5.831   \n",
       "1869        0.298118         19.066             0.098          5.831   \n",
       "1870             NaN            NaN               NaN            NaN   \n",
       "1871             NaN            NaN               NaN            NaN   \n",
       "1872        0.298118         19.066             0.098          5.831   \n",
       "\n",
       "      nearestrefsharp    refjdstart      refjdend  procstatus  \n",
       "0                 NaN  2.458276e+06  2.458348e+06         NaN  \n",
       "1               0.534  2.458285e+06  2.458367e+06         0.0  \n",
       "2               0.534  2.458285e+06  2.458367e+06         0.0  \n",
       "3               0.534  2.458285e+06  2.458367e+06         0.0  \n",
       "4                 NaN  2.458276e+06  2.458348e+06         NaN  \n",
       "...               ...           ...           ...         ...  \n",
       "1868            0.534  2.458285e+06  2.458367e+06         0.0  \n",
       "1869            0.534  2.458285e+06  2.458367e+06         0.0  \n",
       "1870              NaN  2.458276e+06  2.458348e+06         NaN  \n",
       "1871              NaN  2.458276e+06  2.458348e+06         NaN  \n",
       "1872            0.534  2.458285e+06  2.458367e+06         0.0  \n",
       "\n",
       "[1873 rows x 40 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "DATAPATH = os.path.join(PATH,'Data')\n",
    "CODEPATH = os.path.join(PATH,'Code')\n",
    "columns = ['sindex', 'field', 'ccdid', 'qid', 'filter', 'pid', 'infobitssci', 'sciinpseeing', 'scibckgnd', 'scisigpix', 'zpmaginpsci', 'zpmaginpsciunc', 'zpmaginpscirms', 'clrcoeff', 'clrcoeffunc', 'ncalmatches', 'exptime', 'adpctdif1', 'adpctdif2', 'diffmaglim', 'zpdiff', 'programid', 'jd', 'rfid', 'forcediffimflux', 'forcediffimfluxunc', 'forcediffimsnr', 'forcediffimchisq', 'forcediffimfluxap', 'forcediffimfluxuncap', 'forcediffimsnrap', 'aperturecorr', 'dnearestrefsrc', 'nearestrefmag', 'nearestrefmagunc', 'nearestrefchi', 'nearestrefsharp', 'refjdstart', 'refjdend', 'procstatus']\n",
    "dtypes = [(columns[x],float) for x in range(len(columns))]\n",
    "dtypes[4] = ('filter',r'U8')\n",
    "\n",
    "test_path = os.path.join(DATAPATH,r\"18\")\n",
    "test_path = os.path.join(sjoertpath,'ZTF19abiptrq')\n",
    "print(test_path)\n",
    "test_lc = pd.DataFrame(np.genfromtxt(os.path.join(test_path,os.listdir(test_path)[0]),skip_header=53,dtype=dtypes))\n",
    "test_lc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to remove all clean files and clean logs from the sjoert_flares directory.\n",
    "# for folder in os.listdir(sjoertpath)[::-1]:\n",
    "#     if 'ZTF' in folder:\n",
    "#         folderpath = os.path.join(sjoertpath,folder)\n",
    "#         for file in os.listdir(folderpath):\n",
    "#             if 'clean' in file:\n",
    "#                 os.remove(os.path.join(folderpath,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ZTF_r'], dtype=object)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iok = q_cuts(test_lc) * field_check(test_lc)\n",
    "idx_bad = np.where(np.invert(iok))[0]\n",
    "\n",
    "data_ok = test_lc[iok]\n",
    "\n",
    "no_ir_idx = np.where(data_ok['filter'] != 'ZTF_i')[0]\n",
    "data_ok_no_ir = data_ok.copy(deep=True)\n",
    "data_ok_no_ir = data_ok_no_ir.iloc[no_ir_idx]\n",
    "norm_jd_full = np.array(data_ok_no_ir['jd'] - data_ok_no_ir['jd'].iloc[0])\n",
    "\n",
    "clean_data_full = pd.DataFrame({\"time\":norm_jd_full,\"flux\":data_ok_no_ir['forcediffimflux'].values,\n",
    "                                # \"flux_unc\":np.zeros(data_ok_no_ir.shape[0]),\n",
    "                                \"zeropoint\":data_ok_no_ir['zpdiff'].values,\n",
    "                                \"filter\" :data_ok_no_ir['filter'].values})\n",
    "\n",
    "# clean_data_full['flux_unc'].iloc[np.where(clean_data_full['filter'] == 'ZTF_g')[0]] = 1\n",
    "clean_data_full.sort_values('filter',inplace=True)\n",
    "\n",
    "new_unc_tot = []\n",
    "for filter,filter_data in filter_split(data_ok).items():\n",
    "    new_unc = np.array(flux_unc_val(filter_data))\n",
    "    if filter != 'ZTF_i':\n",
    "        new_unc_tot.append(new_unc)\n",
    "new_unc_tot = np.concatenate(new_unc_tot).ravel()\n",
    "clean_data_full['flux_unc'] = new_unc_tot\n",
    "\n",
    "# for item in os.listdir(test_path):\n",
    "#     if 'ZTF_r' in item:\n",
    "#         r_path = os.path.join(test_path,item)\n",
    "#     if 'ZTF_g' in item:\n",
    "#         g_path = os.path.join(test_path,item)\n",
    "#     else:\n",
    "#         continue\n",
    "\n",
    "# rdata = pd.read_csv(r_path,delimiter=' ')\n",
    "# gdata = pd.read_csv(g_path,delimiter=' ')\n",
    "# max(gdata['flux_unc'].values - clean_data_full['flux_unc'].loc[clean_data_full['filter']=='ZTF_g'].values)\n",
    "clean_data_full['filter'].unique() # so it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data,ZTF_ID,filename=None,savepath=None,verbose=False):\n",
    "    iok = q_cuts(data) #very first quality check, mask array of good data points.\n",
    "    data_ok = data[iok]\n",
    "    logdict = {} #dictionary that will form the log.json file\n",
    "\n",
    "    filters = np.unique(data_ok['filter'])\n",
    "\n",
    "    if iok.sum() == 0: #this might occur, this prevents an error\n",
    "        print(f\"{ZTF_ID}: no viable data found in the batch request. Proceeding to next file.\")\n",
    "        return \n",
    "    else:\n",
    "        if 'ZTF_g' not in filters or 'ZTF_r' not in filters:\n",
    "            print(ZTF_ID,\": There is no viable ZTF_g or there is no viable ZTF_r data. Proceeding cleaning.\")\n",
    "\n",
    "    for filter,filtermask in filter_split(data_ok,asmasks=True).items():\n",
    "        logdict[filter] = {}\n",
    "        data_ok_filter = data_ok[filtermask]\n",
    "        fields,field_counts = np.unique(data_ok_filter['field'],return_counts=True)\n",
    "        primary_field = [i == np.max(field_counts) for i in field_counts]\n",
    "\n",
    "        for i,fid in enumerate(fields):\n",
    "            field_mask = data_ok_filter['field'] == fid\n",
    "            data_ok_filter_field = data_ok_filter[field_mask]\n",
    "            iok_filter_field = iok * filtermask * field_mask \n",
    "\n",
    "            if primary_field[i]:\n",
    "                if iok_filter_field.sum() == 0:\n",
    "                    print(f\"{ZTF_ID}: no viable data found in the primary field. Proceeding to next file.\")\n",
    "                    return \n",
    "                else:\n",
    "                    if 'ZTF_g' not in data_ok_filter_field['filter'].unique() or 'ZTF_r' not in data_ok_filter_field['filter'].unique():\n",
    "                        print(ZTF_ID,\": There is no viable ZTF_g or there is no viable ZTF_r data in the primary field. Proceeding cleaning.\")\n",
    "                        for filter,filter_data in filter_split(data_ok).items():\n",
    "                            new_unc = np.array(flux_unc_val(filter_data))\n",
    "\n",
    "                            norm_jd = np.array(filter_data['jd'] - filter_data['jd'].iloc[0])\n",
    "                            clean_data = pd.DataFrame({\"time\":norm_jd,\n",
    "                                                        \"flux\":filter_data['forcediffimflux'].values,\n",
    "                                                        \"flux_unc\":new_unc,\n",
    "                                                        \"zeropoint\":filter_data['zpdiff'].values})\n",
    "                            if savepath != None:\n",
    "                                assert filename != None, 'Filename should be specified if savepath is specified.'\n",
    "                                savestring = os.path.join(savepath,\"clean_\"+filter+\"_\"+filename)\n",
    "                                clean_data.to_csv(savestring,sep=' ',index=False)\n",
    "                            else:\n",
    "                                if verbose:\n",
    "                                    print(filter,clean_data)\n",
    "                                    print(20*'--')\n",
    "                    return\n",
    "\n",
    "            # logdict[filter][fid] = {'ZTF_ID':ZTF_ID,'zeropoint':data_ok_filter_field['zpdiff'],'primary_field':primary_field[i],'removed_cleaning':np.sum(iok_filter_field)},'chi2':15,'chi2_after':14}\n",
    "            # logdict[filter]['chi2'] = ...\n",
    "            # logdict[filter]['chi2_after'] = ...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    idx_bad = np.where(np.invert(iok))[0]\n",
    "\n",
    "    no_ir_idx = np.where(data_ok['filter'] != 'ZTF_i')[0]\n",
    "    data_ok_no_ir = data_ok.copy(deep=True)\n",
    "    data_ok_no_ir = data_ok_no_ir.iloc[no_ir_idx]\n",
    "    try:\n",
    "        norm_jd_full = np.array(data_ok_no_ir['jd'] - data_ok_no_ir['jd'].iloc[0])\n",
    "    except:\n",
    "        if iok.sum() == 0:\n",
    "            print(f\"{savepath}: no viable data found. Proceeding.\")\n",
    "            return \n",
    "        else:\n",
    "            if 'ZTF_g' not in data_ok['filter'].unique() or 'ZTF_r' not in data_ok['filter'].unique():\n",
    "                print(\"There is no viable ZTF_g or there is no viable ZTF_r data. Proceeding cleaning.\")\n",
    "                for filter,filter_data in filter_split(data_ok).items():\n",
    "                    new_unc = np.array(flux_unc_val(filter_data))\n",
    "\n",
    "                    norm_jd = np.array(filter_data['jd'] - filter_data['jd'].iloc[0])\n",
    "                    clean_data = pd.DataFrame({\"time\":norm_jd,\n",
    "                                                \"flux\":filter_data['forcediffimflux'].values,\n",
    "                                                \"flux_unc\":new_unc,\n",
    "                                                \"zeropoint\":filter_data['zpdiff'].values})\n",
    "                    if savepath != None:\n",
    "                        assert filename != None\n",
    "                        savestring = os.path.join(savepath,\"clean_\"+filter+\"_\"+filename)\n",
    "                        clean_data.to_csv(savestring,sep=' ',index=False)\n",
    "                    else:\n",
    "                        if verbose:\n",
    "                            print(filter,clean_data)\n",
    "                            print(20*'--')\n",
    "                return\n",
    "\n",
    "\n",
    "    clean_data_full = pd.DataFrame({\"time\":norm_jd_full,\"flux\":data_ok_no_ir['forcediffimflux'].values,\n",
    "                                # \"flux_unc\":np.zeros(data_ok_no_ir.shape[0]),\n",
    "                                \"zeropoint\":data_ok_no_ir['zpdiff'].values,\n",
    "                                \"filter\" :data_ok_no_ir['filter'].values})\n",
    "\n",
    "    if savepath != None:\n",
    "        pd.DataFrame({\"bad_idx\":[idx_bad],\"median_chi_before\":np.median(data['forcediffimchisq']),\"median_chi_after\":np.median(data_ok['forcediffimchisq'])}).to_csv(\\\n",
    "            os.path.join(savepath,'clean_log.txt'),sep=' ',index=False)\n",
    "\n",
    "    new_unc_tot = []\n",
    "\n",
    "    for filter,filter_data in filter_split(data_ok).items():\n",
    "        new_unc = np.array(flux_unc_val(filter_data))\n",
    "        if filter != 'ZTF_i':\n",
    "            new_unc_tot.append(new_unc)\n",
    "\n",
    "        norm_jd = np.array(filter_data['jd'] - filter_data['jd'].iloc[0])\n",
    "        clean_data = pd.DataFrame({\"time\":norm_jd,\n",
    "                                    \"flux\":filter_data['forcediffimflux'].values,\n",
    "                                    \"flux_unc\":new_unc,\n",
    "                                    \"zeropoint\":filter_data['zpdiff'].values})\n",
    "        \n",
    "        if savepath != None:\n",
    "            assert filename != None\n",
    "            savestring = os.path.join(savepath,\"clean_\"+filter+\"_\"+filename)\n",
    "            clean_data.to_csv(savestring,sep=' ',index=False)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(filter,clean_data)\n",
    "                print(20*'--')\n",
    "\n",
    "    new_unc_tot = np.concatenate(new_unc_tot).ravel()\n",
    "    clean_data_full['flux_unc'] = new_unc_tot\n",
    "\n",
    "    if savepath != None:\n",
    "        savestring = os.path.join(savepath,\"clean_g_and_r\"+filename)\n",
    "        clean_data_full.to_csv(savestring,sep=' ',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DIT MOET NOG GEUPDATET WORDEN:\n",
    "\"\"\"\n",
    "Het moet nu zo zijn dat clean data alle bad points er uit haalt en een file kan saven wat niet gesplit is op filters (behalve dat i er uit is).\n",
    "Dan moet nog steeds de uncertainty validation gedaan worden en dat gaat filter gewijs. Vogel uit hoe je dit gaat doen. Verder wil je bij elk \n",
    "punt in de clean data dus hebben staan vanuit welke filter het komt (dit gaan we later nodig hebben voor fitten.)\n",
    "In de log moet ook (per filter) de start en eind datum van de referentie (dit voor baseline meuk.)\n",
    "\"\"\"\n",
    "\n",
    "def clean_data(data,filename=None,savepath=None,verbose=False):\n",
    "    iok = q_cuts(data) * field_check(data)\n",
    "    idx_bad = np.where(np.invert(iok))[0]\n",
    "\n",
    "    data_ok = data[iok]\n",
    "\n",
    "    no_ir_idx = np.where(data_ok['filter'] != 'ZTF_i')[0]\n",
    "    data_ok_no_ir = data_ok.copy(deep=True)\n",
    "    data_ok_no_ir = data_ok_no_ir.iloc[no_ir_idx]\n",
    "    try:\n",
    "        norm_jd_full = np.array(data_ok_no_ir['jd'] - data_ok_no_ir['jd'].iloc[0])\n",
    "    except:\n",
    "        if iok.sum() == 0:\n",
    "            print(f\"{savepath}: no viable data found. Proceeding.\")\n",
    "            return \n",
    "        else:\n",
    "            if 'ZTF_g' not in data_ok['filter'].unique() or 'ZTF_r' not in data_ok['filter'].unique():\n",
    "                print(\"There is no viable ZTF_g or there is no viable ZTF_r data. Proceeding cleaning.\")\n",
    "                for filter,filter_data in filter_split(data_ok).items():\n",
    "                    new_unc = np.array(flux_unc_val(filter_data))\n",
    "\n",
    "                    norm_jd = np.array(filter_data['jd'] - filter_data['jd'].iloc[0])\n",
    "                    clean_data = pd.DataFrame({\"time\":norm_jd,\n",
    "                                                \"flux\":filter_data['forcediffimflux'].values,\n",
    "                                                \"flux_unc\":new_unc,\n",
    "                                                \"zeropoint\":filter_data['zpdiff'].values})\n",
    "                    if savepath != None:\n",
    "                        assert filename != None, 'Filename should be specified if savepath is specified.'\n",
    "                        savestring = os.path.join(savepath,\"clean_\"+filter+\"_\"+filename)\n",
    "                        clean_data.to_csv(savestring,sep=' ',index=False)\n",
    "                    else:\n",
    "                        if verbose:\n",
    "                            print(filter,clean_data)\n",
    "                            print(20*'--')\n",
    "                return\n",
    "\n",
    "\n",
    "    clean_data_full = pd.DataFrame({\"time\":norm_jd_full,\"flux\":data_ok_no_ir['forcediffimflux'].values,\n",
    "                                # \"flux_unc\":np.zeros(data_ok_no_ir.shape[0]),\n",
    "                                \"zeropoint\":data_ok_no_ir['zpdiff'].values,\n",
    "                                \"filter\" :data_ok_no_ir['filter'].values})\n",
    "\n",
    "    if savepath != None:\n",
    "        pd.DataFrame({\"bad_idx\":[idx_bad],\"median_chi_before\":np.median(data['forcediffimchisq']),\"median_chi_after\":np.median(data_ok['forcediffimchisq'])}).to_csv(\\\n",
    "            os.path.join(savepath,'clean_log.txt'),sep=' ',index=False)\n",
    "\n",
    "    new_unc_tot = []\n",
    "\n",
    "    for filter,filter_data in filter_split(data_ok).items():\n",
    "        new_unc = np.array(flux_unc_val(filter_data))\n",
    "        if filter != 'ZTF_i':\n",
    "            new_unc_tot.append(new_unc)\n",
    "\n",
    "        norm_jd = np.array(filter_data['jd'] - filter_data['jd'].iloc[0])\n",
    "        clean_data = pd.DataFrame({\"time\":norm_jd,\n",
    "                                    \"flux\":filter_data['forcediffimflux'].values,\n",
    "                                    \"flux_unc\":new_unc,\n",
    "                                    \"zeropoint\":filter_data['zpdiff'].values})\n",
    "        \n",
    "        if savepath != None:\n",
    "            assert filename != None\n",
    "            savestring = os.path.join(savepath,\"clean_\"+filter+\"_\"+filename)\n",
    "            clean_data.to_csv(savestring,sep=' ',index=False)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(filter,clean_data)\n",
    "                print(20*'--')\n",
    "\n",
    "    new_unc_tot = np.concatenate(new_unc_tot).ravel()\n",
    "    clean_data_full['flux_unc'] = new_unc_tot\n",
    "\n",
    "    if savepath != None:\n",
    "        savestring = os.path.join(savepath,\"clean_g_and_r\"+filename)\n",
    "        clean_data_full.to_csv(savestring,sep=' ',index=False)\n",
    "\n",
    "clean_data(test_lc,verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timvd\\Documents\\Uni 2023-2024\\First Research Project\\Data\\Sjoert_Flares\\ZTF19abisdrk: no viable data found. Proceeding.\n"
     ]
    }
   ],
   "source": [
    "sjoertpath = r'C:\\Users\\timvd\\Documents\\Uni 2023-2024\\First Research Project\\Data\\Sjoert_Flares'\n",
    "sjoertflares = pd.read_csv(r'C:\\Users\\timvd\\Documents\\Uni 2023-2024\\First Research Project\\Data\\ZTF_neoWISE_flares_acflares.dat',delimiter=' ')\n",
    "catalog_coords = coord.SkyCoord(np.array(sjoertflares['ra']),np.array(sjoertflares['dec']),unit='deg')\n",
    "\n",
    "for folder in os.listdir(sjoertpath)[::-1]:\n",
    "    if \"ZTF\" in folder:\n",
    "        folderpath = os.path.join(sjoertpath,folder)\n",
    "        for file in os.listdir(folderpath):\n",
    "            if 'clean' not in file:\n",
    "                filepath = os.path.join(folderpath,file)\n",
    "                test = np.genfromtxt(filepath,skip_header=53,dtype=dtypes)\n",
    "                data = pd.DataFrame(np.genfromtxt(filepath,skip_header=53,dtype=dtypes))\n",
    "                clean_data(data,filename=file,savepath=folderpath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZTF19abisdrk first\n",
      "ZTF19abisdrk second\n",
      "\n",
      "ZTF19aaohxwd first\n",
      "ZTF19aaohxwd second\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir(sjoertpath)[::-1]:\n",
    "    if \"ZTF\" in folder:\n",
    "        folderpath = os.path.join(sjoertpath,folder)\n",
    "        if len(os.listdir(folderpath)) < 5:\n",
    "            if True not in ['clean_ZTF_i' in name for name in os.listdir(folderpath)]:\n",
    "                print(folder,'first')\n",
    "            print(folder,'second')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now performing the whole photometry business on the one with cleaned files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flux_jy(data):\n",
    "    zp = sjoert.stellar.mag2flux(data['zeropoint'])\n",
    "    flux = zp * data['flux'] * 1e6\n",
    "    err = zp * data['flux_unc'] * 1e6\n",
    "    return flux,err\n",
    "\n",
    "def plot_clean_data(data,folder,file,savefig = False,verbose=False):\n",
    "    flux,err = flux_jy(data)\n",
    "    filter = file[10:][:1]\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"time (jd)\")\n",
    "    plt.ylabel(\"Flux (mJy)\")\n",
    "    plt.title(folder + ' - ' + filter.upper() + \" filter\")\n",
    "    plt.errorbar(data['time'],flux,err,fmt='.')\n",
    "    if verbose and not savefig:\n",
    "        plt.show()\n",
    "    if savefig:\n",
    "        plt.savefig(os.path.join(sjoertpath,\"first_run_plots\",folder+\"_\"+filter.upper()+\" filter.png\"),dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "testdir = r'C:\\Users\\timvd\\Documents\\Uni 2023-2024\\First Research Project\\Data\\Sjoert_Flares\\ZTF20aagkqky'\n",
    "for folder in os.listdir(sjoertpath):\n",
    "    if \"ZTF\" in folder:\n",
    "        folderpath = os.path.join(sjoertpath,folder)\n",
    "        for file in os.listdir(folderpath):\n",
    "            if 'clean' in file and 'log' not in file:\n",
    "                data = pd.read_csv(os.path.join(folderpath,file),delimiter=' ')\n",
    "                plot_clean_data(data,folder,file,0,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
